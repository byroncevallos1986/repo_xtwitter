name: Ejecutar Twitter BigQuery Diario

on:
  schedule:
    # Ejecutar todos los d√≠as a las 00:00:00 UTC
    - cron: "0 0 * * *"
  workflow_dispatch:  # Permite ejecuci√≥n manual desde la pesta√±a "Actions"

jobs:
  run-script:
    runs-on: ubuntu-latest

    steps:
      # üß± 1Ô∏è‚É£ Clonar el repositorio
      - name: Checkout del repositorio
        uses: actions/checkout@v4

      # üêç 2Ô∏è‚É£ Configurar Python
      - name: Configurar Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      # üì¶ 3Ô∏è‚É£ Instalar dependencias
      - name: Instalar dependencias
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # üîë 4Ô∏è‚É£ Configurar credenciales de Google Cloud (BigQuery)
      # ‚ö†Ô∏è Debes agregar tu JSON de servicio como un secreto llamado GOOGLE_APPLICATION_CREDENTIALS_JSON
      - name: Crear archivo de credenciales
        env:
          # Carga el secreto en una variable de entorno limpia para este paso
          GCP_JSON_KEY: ${{ secrets.GOOGLE_APPLICATION_CREDENTIALS_JSON }}
        run: |
          # Escribe el contenido de la variable de entorno al archivo
          echo "$GCP_JSON_KEY" > service_account.json
        shell: bash

      # üìÅ 5Ô∏è‚É£ Crear archivo temporal para logs
      - name: Crear archivo de log vac√≠o
        run: echo "Inicio de ejecuci√≥n del workflow" > xlog.log

      # üöÄ 6Ô∏è‚É£ Ejecutar script principal
      - name: Ejecutar main.py
        env:
          GOOGLE_APPLICATION_CREDENTIALS: ${{ github.workspace }}/service_account.json
          BEARER_TOKEN_1: ${{ secrets.BEARER_TOKEN_1 }}
          BEARER_TOKEN_2: ${{ secrets.BEARER_TOKEN_2 }}
        run: |
          python main.py

      # üì§ 7Ô∏è‚É£ Subir archivo de logs como artifact
      - name: Subir log como artifact
        uses: actions/upload-artifact@v4
        with:
          name: xlog-log
          path: xlog.log
          retention-days: 7
